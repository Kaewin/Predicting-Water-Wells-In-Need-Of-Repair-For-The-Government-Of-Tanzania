{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro:\n",
    "\n",
    "## Business Problem: Predicting Water Wells In Need Of Repair For The Government Of Tanzania\n",
    "\n",
    "## Stakeholder: The Ministry Of Water in Tanzania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_target = pd.read_csv('./Data/training_set_labels.csv')\n",
    "df_train_data = pd.read_csv('./Data/training_set_values.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapsing The Target Categories\n",
    "\n",
    "The goal is to predict wells that require repair.\n",
    "\n",
    "The target variable is `status_group` which has three categories:\n",
    "\n",
    "- `functional`\n",
    "- `functional needs repair`\n",
    "- `non functional`\n",
    "\n",
    "I will collapse the categories `functional needs repair` and `non functional` into one category `needs repair` to create a binary target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 32259\n",
       "non functional             22824\n",
       "functional needs repair     4317\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at df_train_target\n",
    "df_train_target['status_group'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional    32259\n",
       "repair        27141\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the name of the status_group in df_train_target 'functional needs repair' to 'repair'\n",
    "# Also change the name of 'non functional' to non-functional\n",
    "df_train_target['status_group'] = df_train_target['status_group'].replace('functional needs repair', 'repair')\n",
    "df_train_target['status_group'] = df_train_target['status_group'].replace('non functional', 'repair')\n",
    "\n",
    "# Check\n",
    "df_train_target['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.543081\n",
       "1    0.456919\n",
       "Name: status_group, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode status_group as 0, 1\n",
    "df_train_target['status_group'] = df_train_target['status_group'].astype('category')\n",
    "df_train_target['status_group'] = df_train_target['status_group'].cat.codes\n",
    "\n",
    "# Check\n",
    "df_train_target['status_group'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I have collapsed the target categories, and I have encoded the target variable as a binary variable.\n",
    "\n",
    "Also note that the target variable is not imbalanced."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines:\n",
    "\n",
    "Time to set up some pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer,  make_column_selector as selector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix, recall_score,\\\n",
    "    accuracy_score, precision_score, f1_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating The pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpipe_numerics = Pipeline(steps = [\n",
    "    ('num_impute', SimpleImputer(strategy='median')),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "subpipe_cat = Pipeline(steps=[\n",
    "    ('cat_impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT = ColumnTransformer(transformers=[\n",
    "    ('subpipe_num', subpipe_numerics, selector(dtype_include=np.number)),\n",
    "    ('subpipe_cat', subpipe_cat, selector(dtype_include=object))\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Model Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model_pipe = Pipeline(steps=[\n",
    "    ('ct',CT),\n",
    "    ('dummy', DummyClassifier(strategy='most_frequent'))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logreg model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model_pipe = Pipeline(steps=[\n",
    "    ('ct',CT),\n",
    "    ('fsm', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's put in the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test, Train, And Validation Split:\n",
    "\n",
    "I will split the data into three sets:\n",
    "\n",
    "- train 15%\n",
    "- validation 15%\n",
    "- test 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35343, 40)\n",
      "(6237, 40)\n",
      "(17820, 40)\n"
     ]
    }
   ],
   "source": [
    "# Perform a 15-15-70 split on the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train_data\n",
    "y = df_train_target['status_group']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=77)\n",
    "\n",
    "# Now split again to create a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=77)\n",
    "\n",
    "# Check the shapes\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54344566109272"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the dummy model pipeline to the data\n",
    "dummy_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Check the score\n",
    "dummy_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logreg Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the logreg pipeline to the data\n",
    "logreg_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Check the score\n",
    "logreg_model_pipe.score(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
